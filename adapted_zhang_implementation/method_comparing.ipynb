{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419a4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sofi/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Seed used: 1764881139\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import configparser\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from state_env import State\n",
    "from RL_brain_pi_deep import DQNPrioritizedReplay\n",
    "\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=['blue', 'red', 'black', 'green', 'magenta', 'yellow', 'black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61c21a",
   "metadata": {},
   "source": [
    "# Comparison of single model using both methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f018d1f",
   "metadata": {},
   "source": [
    "This notebook focuses on comparing a trained DRL model with the results obtained using the genetic algorithm method. \n",
    "In the following cell, one should specify the directory containing the GA solutions and the directory containing the trained DRL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983afa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of directories for GA and DRL\n",
    "# Example usage: fill these lists with the directories you want to compare\n",
    "list_genetic_resulting_directories = [\n",
    "    '../genetic_algorithm/results/reward_based_fitness_oaps_actions_99',\n",
    "    '../genetic_algorithm/results/reward_based_fitness_zhang_actions_99',\n",
    "]\n",
    "ga_labels = ['(action-by-site)', '(Zhang actions)']\n",
    "list_trained_drl_directories = [\n",
    "    '../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps',\n",
    "    '../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna',\n",
    "]\n",
    "rl_labels = ['Opt. DRL (p,a = 0.25) action-by-site ', 'Opt. DRL (p,a = 0.25) Zhang actions']\n",
    "\n",
    "# chain length (since ga directories include results for different chain lengths)\n",
    "chain_length = 16\n",
    "val_episodes = 100  # default, can be changed\n",
    "\n",
    "ga_solutions_list = []\n",
    "ga_config_instances = []\n",
    "for genetic_resulting_directory in list_genetic_resulting_directories:\n",
    "    ga_solutions_path = os.path.join(genetic_resulting_directory, f'n{chain_length}.txt')\n",
    "    ga_solutions = np.loadtxt(ga_solutions_path)\n",
    "    ga_solutions_list.append(ga_solutions)\n",
    "    ga_ini_file = os.path.join(genetic_resulting_directory, f'n{chain_length}.ini')\n",
    "    ga_config_instance = configparser.ConfigParser()\n",
    "    ga_config_instance.read(ga_ini_file)\n",
    "    ga_config_instances.append(ga_config_instance)\n",
    "\n",
    "rl_best_solutions_list = []\n",
    "rl_config_instances = []\n",
    "rl_ini_paths = []\n",
    "for trained_drl_directory in list_trained_drl_directories:\n",
    "    ini_files = [f for f in os.listdir(trained_drl_directory) if f.endswith('.ini')]\n",
    "    if not ini_files:\n",
    "        raise FileNotFoundError(f\"No .ini file found in {trained_drl_directory}\")\n",
    "    rl_ini_path = os.path.join(trained_drl_directory, ini_files[0])\n",
    "    rl_ini_paths.append(rl_ini_path)\n",
    "    rl_config_instance = configparser.ConfigParser()\n",
    "    rl_config_instance.read(rl_ini_path)\n",
    "    rl_config_instances.append(rl_config_instance)\n",
    "    rl_best_solutions = np.loadtxt(os.path.join(trained_drl_directory, 'best_action_sequences.txt'))\n",
    "    rl_best_solutions_list.append(rl_best_solutions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37134e",
   "metadata": {},
   "source": [
    "### Fixed noise probability (variable amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c70891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sofi/.local/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 17:45:40.219883: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3693165000 Hz\n",
      "2025-12-04 17:45:40.220583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ff6498310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-04 17:45:40.220615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_optuna/best_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "noise_steps = 10\n",
    "noise_amplitude_values = np.linspace(0, 0.5, noise_steps)\n",
    "fixed_probability_value = 0.25\n",
    "fs = 14\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# DRL comparison for each directory\n",
    "for idx, (rl_config_instance, trained_drl_directory, rl_label) in enumerate(zip(rl_config_instances, list_trained_drl_directories, rl_labels)):\n",
    "    mean_fids = []\n",
    "    std_fids = []\n",
    "    for noise_amplitude in noise_amplitude_values:\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        if not rl_config_instance.has_section('noise_parameters'):\n",
    "            rl_config_instance.add_section('noise_parameters')\n",
    "        rl_config_instance.set('noise_parameters', 'noise', 'True')\n",
    "        rl_config_instance.set('noise_parameters', 'noise_amplitude', str(noise_amplitude))\n",
    "        rl_config_instance.set('noise_parameters', 'noise_probability', str(fixed_probability_value))\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            RL_val = DQNPrioritizedReplay(config_instance=rl_config_instance, sess=sess)\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            checkpoint_path = os.path.join(trained_drl_directory, 'best_model', 'model.ckpt')\n",
    "            saver.restore(sess, checkpoint_path)\n",
    "            env = State(config_instance=rl_config_instance)\n",
    "            max_t_steps = rl_config_instance.getint('system_parameters', 'max_t_steps')\n",
    "            max_fids = []\n",
    "            for episode in range(val_episodes):\n",
    "                observation = env.reset()\n",
    "                fid_max = 0\n",
    "                for i in range(max_t_steps):\n",
    "                    action = RL_val.choose_action(observation, eval=True)\n",
    "                    observation_, reward, fidelity = env.step(action)\n",
    "                    observation = observation_.copy()\n",
    "                    if fidelity > fid_max:\n",
    "                        fid_max = fidelity\n",
    "                max_fids.append(fid_max)\n",
    "            mean_fids.append(np.mean(max_fids))\n",
    "            std_fids.append(np.std(max_fids))\n",
    "    plt.errorbar(noise_amplitude_values, mean_fids, yerr=std_fids, marker='o', label=f'{rl_label}', capsize=4)\n",
    "\n",
    "# GA comparison for each directory\n",
    "def ga_sweep(ga_solutions, ga_config_instance):\n",
    "    mean_fids = []\n",
    "    std_fids = []\n",
    "    for noise_amplitude in noise_amplitude_values:\n",
    "        if not ga_config_instance.has_section('noise_parameters'):\n",
    "            ga_config_instance.add_section('noise_parameters')\n",
    "        ga_config_instance.set('noise_parameters', 'noise', 'True')\n",
    "        ga_config_instance.set('noise_parameters', 'noise_amplitude', str(noise_amplitude))\n",
    "        ga_config_instance.set('noise_parameters', 'noise_probability', str(fixed_probability_value))\n",
    "        env = State(config_instance=ga_config_instance)\n",
    "        max_t_steps = ga_config_instance.getint('system_parameters', 'max_t_steps')\n",
    "        max_fids = []\n",
    "        for ga_solution in range(np.shape(ga_solutions)[0]):\n",
    "            observation = env.reset()\n",
    "            fid_max = 0\n",
    "            for i in range(max_t_steps):\n",
    "                action = int(ga_solutions[ga_solution, i])\n",
    "                observation_, reward, fidelity = env.step(action)\n",
    "                observation = observation_.copy()\n",
    "                if fidelity > fid_max:\n",
    "                    fid_max = fidelity\n",
    "            max_fids.append(fid_max)\n",
    "        mean_fids.append(np.mean(max_fids))\n",
    "        std_fids.append(np.std(max_fids))\n",
    "    return mean_fids, std_fids\n",
    "\n",
    "for idx, (ga_solutions, ga_config_instance, ga_label) in enumerate(zip(ga_solutions_list, rl_config_instances, ga_labels)):\n",
    "    mean_fids, std_fids = ga_sweep(ga_solutions, ga_config_instance)\n",
    "    plt.errorbar(noise_amplitude_values, mean_fids, yerr=std_fids, marker='x', label=f'GA {ga_label}', capsize=4)\n",
    "\n",
    "plt.xlabel('Noise Amplitude [a]', fontsize=fs)\n",
    "#plt.title(f'Mean Max Fidelity vs Noise Amplitude (Probability={fixed_probability_value})', fontsize=fs)\n",
    "plt.ylabel('Fidelidad Media [P]', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.title(f'Cadena de {chain_length} Qubits', fontsize=fs)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110118e8",
   "metadata": {},
   "source": [
    "Fixed noise amplitude (variable probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../adapted_zhang_implementation/modelos_exitosos/n16_25amp_25prob_opt_oaps/best_model/model.ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3739101/1514227112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mfid_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_t_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRL_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/codigos/qst_control/adapted_zhang_implementation/RL_brain_pi_deep.py\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, observation, eval)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mactions_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_steps = 10\n",
    "noise_probability_values = np.linspace(0, 1, noise_steps)\n",
    "fixed_amplitude_value = 0.25\n",
    "fs = 12\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# DRL comparison for each directory\n",
    "for idx, (rl_config_instance, trained_drl_directory, rl_labels) in enumerate(zip(rl_config_instances, list_trained_drl_directories, rl_labels)):\n",
    "    mean_fids = []\n",
    "    std_fids = []\n",
    "    for noise_probability in noise_probability_values:\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        if not rl_config_instance.has_section('noise_parameters'):\n",
    "            rl_config_instance.add_section('noise_parameters')\n",
    "        rl_config_instance.set('noise_parameters', 'noise', 'True')\n",
    "        rl_config_instance.set('noise_parameters', 'noise_probability', str(noise_probability))\n",
    "        rl_config_instance.set('noise_parameters', 'noise_amplitude', str(fixed_amplitude_value))\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            RL_val = DQNPrioritizedReplay(config_instance=rl_config_instance, sess=sess)\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            checkpoint_path = os.path.join(trained_drl_directory, 'best_model', 'model.ckpt')\n",
    "            saver.restore(sess, checkpoint_path)\n",
    "            env = State(config_instance=rl_config_instance)\n",
    "            max_t_steps = rl_config_instance.getint('system_parameters', 'max_t_steps')\n",
    "            max_fids = []\n",
    "            for episode in range(val_episodes):\n",
    "                observation = env.reset()\n",
    "                fid_max = 0\n",
    "                for i in range(max_t_steps):\n",
    "                    action = RL_val.choose_action(observation, eval=True)\n",
    "                    observation_, reward, fidelity = env.step(action)\n",
    "                    observation = observation_.copy()\n",
    "                    if fidelity > fid_max:\n",
    "                        fid_max = fidelity\n",
    "                max_fids.append(fid_max)\n",
    "            mean_fids.append(np.mean(max_fids))\n",
    "            std_fids.append(np.std(max_fids))\n",
    "    plt.errorbar(noise_probability_values, mean_fids, yerr=std_fids, marker='o', label=f'DRL {rl_labels}', capsize=4)\n",
    "\n",
    "# GA comparison for each directory\n",
    "for idx, (ga_solutions, ga_config_instance, ga_label) in enumerate(zip(ga_solutions_list, rl_config_instances, ga_labels)):\n",
    "    mean_fids = []\n",
    "    std_fids = []\n",
    "    for noise_probability in noise_probability_values:\n",
    "        \n",
    "        if not ga_config_instance.has_section('noise_parameters'):\n",
    "            ga_config_instance.add_section('noise_parameters')\n",
    "            \n",
    "        ga_config_instance.set('noise_parameters', 'noise', 'True')\n",
    "        ga_config_instance.set('noise_parameters', 'noise_probability', str(noise_probability))\n",
    "        ga_config_instance.set('noise_parameters', 'noise_amplitude', str(fixed_amplitude_value))\n",
    "        env = State(config_instance=ga_config_instance)\n",
    "        max_t_steps = ga_config_instance.getint('system_parameters', 'max_t_steps')\n",
    "        max_fids = []\n",
    "        for ga_solution in range(np.shape(ga_solutions)[0]):\n",
    "            observation = env.reset()\n",
    "            fid_max = 0\n",
    "            for i in range(max_t_steps):\n",
    "                action = int(ga_solutions[ga_solution, i])\n",
    "                observation_, reward, fidelity = env.step(action)\n",
    "                observation = observation_.copy()\n",
    "                if fidelity > fid_max:\n",
    "                    fid_max = fidelity\n",
    "            max_fids.append(fid_max)\n",
    "        mean_fids.append(np.mean(max_fids))\n",
    "        std_fids.append(np.std(max_fids))\n",
    "    plt.errorbar(noise_probability_values, mean_fids, yerr=std_fids, marker='x', label=f'GA {ga_label}', capsize=4)\n",
    "\n",
    "plt.xlabel('Noise probability', fontsize=fs)\n",
    "plt.title(f'Mean Max Fidelity vs Noise probability (amplitude={fixed_amplitude_value})', fontsize=fs)\n",
    "plt.ylabel('Mean Max Fidelity', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06473ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd667b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_evolution(sequence, env, add_natural=False):\n",
    "    \n",
    "    fidelity_evolution = []\n",
    "    observation = env.reset()\n",
    "    fid_max = 0\n",
    "    \n",
    "    for action in sequence:\n",
    "        action = int(action)\n",
    "        observation_, reward, fidelity = env.step(action)\n",
    "        observation = observation_.copy()\n",
    "        fidelity_evolution.append(fidelity)\n",
    "\n",
    "    natural_evolution = None\n",
    "    if add_natural:\n",
    "        natural_evolution = []\n",
    "        observation = env.reset()\n",
    "        for _ in sequence:\n",
    "            observation_, reward, fidelity = env.step(0)\n",
    "            observation = observation_.copy()\n",
    "            natural_evolution.append(fidelity)\n",
    "            \n",
    "    return fidelity_evolution, natural_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe81504",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSectionError",
     "evalue": "No section: 'learning_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSectionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72742/2601919374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mga_solutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga_config_instance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mga_solutions_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga_config_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mga_config_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mforced_evol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnatural_evol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mga_solutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_natural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforced_evol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'GA {idx+1} sample {sample}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/codigos/qst_control/adapted_zhang_implementation/state_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config_instance)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         reward_function = config_instance.get(\"learning_parameters\",\n\u001b[0;32m---> 70\u001b[0;31m                                               \"reward_function\")\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreward_function\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"original\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfopt/lib/python3.7/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unify_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfopt/lib/python3.7/configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[0;34m(self, section, vars)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_section\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;31m# Update with the entry specific variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mvardict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSectionError\u001b[0m: No section: 'learning_parameters'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "samples = np.arange(10)\n",
    "fs = 12\n",
    "\n",
    "# Store the last natural_evol for plotting outside the loop\n",
    "last_natural_evol = None\n",
    "\n",
    "# Plot GA samples for each directory\n",
    "for idx, (ga_solutions, ga_config_instance) in enumerate(zip(ga_solutions_list, ga_config_instances)):\n",
    "    for sample in samples:\n",
    "        env = State(config_instance=ga_config_instance)\n",
    "        forced_evol, natural_evol = fid_evolution(ga_solutions[sample][:], env, add_natural=True)\n",
    "        plt.plot(forced_evol, '-o', label=f'GA {idx+1} sample {sample}', color='red', alpha=0.3, linewidth=1.2, markersize=0.2)\n",
    "        last_natural_evol = natural_evol  # Save the last one for plotting\n",
    "\n",
    "# Plot DRL samples for each directory\n",
    "for idx, (rl_best_solutions, rl_config_instance) in enumerate(zip(rl_best_solutions_list, rl_config_instances)):\n",
    "    for sample in samples:\n",
    "        env = State(config_instance=rl_config_instance)\n",
    "        forced_evol, natural_evol = fid_evolution(rl_best_solutions[sample][:], env, add_natural=True)\n",
    "        plt.plot(forced_evol, '-o', label=f'DRL {idx+1} sample {sample}', color='blue', alpha=0.3, linewidth=1.2, markersize=0.2)\n",
    "\n",
    "if last_natural_evol is not None:\n",
    "    plt.plot(last_natural_evol, '-o', label='Natural', color='green', alpha=0.5, linewidth=5, markersize=0.2, zorder=-2)\n",
    "\n",
    "plt.xlabel('Paso Temporal / Cantidad de pulsos', fontsize=fs)\n",
    "plt.ylabel('Fidelidad', fontsize=fs)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='red', lw=1.2, label='GA'),\n",
    "    Line2D([0], [0], color='blue', lw=1.2, label='DRL'),\n",
    "    Line2D([0], [0], color='green', lw=1.5, label='Natural')\n",
    "]\n",
    "plt.legend(handles=legend_elements, fontsize=fs, loc='lower left', bbox_to_anchor=(0, 0.1))\n",
    "plt.text(0.02, 0.09, '(b)', transform=plt.gca().transAxes, fontsize=fs, verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "plt.title(f'Probabilidades de transici√≥n para N={chain_length}', fontsize=fs)\n",
    "\n",
    "# Agregar inset\n",
    "ax_inset = inset_axes(plt.gca(), width=\"40%\", height=\"50%\", loc=\"upper left\")\n",
    "if last_natural_evol is not None:\n",
    "    ax_inset.plot(range(len(last_natural_evol))[int(-2.5*chain_length):], last_natural_evol[int(-2.5*chain_length):], '-o', label='Natural', color='green', alpha=0.5, linewidth=5, markersize=0.2, zorder=-2)\n",
    "for idx, (ga_solutions, ga_config_instance) in enumerate(zip(ga_solutions_list, ga_config_instances)):\n",
    "    for sample in samples:\n",
    "        env = State(config_instance=ga_config_instance)\n",
    "        forced_evol, _ = fid_evolution(ga_solutions[sample][:], env, add_natural=False)\n",
    "        ax_inset.plot(range(len(forced_evol))[int(-2.5*chain_length):], forced_evol[int(-2.5*chain_length):], '-o', color='red', alpha=0.3, linewidth=1.2, markersize=0.2)\n",
    "for idx, (rl_best_solutions, rl_config_instance) in enumerate(zip(rl_best_solutions_list, rl_config_instances)):\n",
    "    for sample in samples:\n",
    "        env = State(config_instance=rl_config_instance)\n",
    "        forced_evol, _ = fid_evolution(rl_best_solutions[sample][:], env, add_natural=False)\n",
    "        ax_inset.plot(range(len(forced_evol))[int(-2.5*chain_length):], forced_evol[int(-2.5*chain_length):], '-o', color='blue', alpha=0.3, linewidth=1.2, markersize=0.2)\n",
    "ax_inset.yaxis.tick_right()\n",
    "ax_inset.tick_params(axis='both', which='major', labelsize=fs - 6)\n",
    "ax_inset.set_yticks([0., 0.5, 0.95])\n",
    "ax_inset.tick_params(axis='x', labelsize=fs - 6)\n",
    "ax_inset.tick_params(axis='y', labelsize=fs - 6)\n",
    "plt.xticks(fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.tight_layout(pad=6.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322af4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
